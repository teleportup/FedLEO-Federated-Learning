import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import time

print(f"üöÄ TensorFlow version: {tf.__version__}\n")

class SatelliteV2:
    """–°–ø—É—Ç–Ω–∏–∫ v2.0 - –æ–±—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ –æ—Ä–±–∏—Ç–µ"""
    def __init__(self, sat_id, model, local_data, local_labels):
        self.sat_id = sat_id
        self.model = model
        self.local_data = local_data
        self.local_labels = local_labels
        self.local_dataset_size = len(local_data)
        self.training_history = {'loss': [], 'accuracy': [], 'time': []}
        self.orbital_altitude = 400 + sat_id * 50
        self.total_training_time = 0
        self.weights_sent = 0
        print(f"üõ∞Ô∏è  –°–ø—É—Ç–Ω–∏–∫ {sat_id} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω | –î–∞–Ω–Ω—ã–µ: {self.local_dataset_size} | –í—ã—Å–æ—Ç–∞: {self.orbital_altitude} –∫–º")
    
    def receive_weights(self, weights):
        """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å–∞ —Å –ó–µ–º–ª–∏"""
        self.model.set_weights(weights)
    
    def train_on_satellite(self, epochs=1, lr=0.01):
        """‚≠ê –ì–õ–ê–í–ù–û–ï: –õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–µ"""
        start = time.time()
        
        self.model.compile(
            optimizer=keras.optimizers.SGD(learning_rate=lr),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        history = self.model.fit(
            self.local_data, self.local_labels,
            epochs=epochs, verbose=0, batch_size=32, shuffle=True
        )
        
        train_time = time.time() - start
        self.total_training_time += train_time
        
        loss = history.history['loss'][-1]
        acc = history.history['accuracy'][-1]
        
        self.training_history['loss'].append(loss)
        self.training_history['accuracy'].append(acc)
        self.training_history['time'].append(train_time)
        
        return {'loss': loss, 'accuracy': acc, 'time': train_time}
    
    def send_weights(self):
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–µ—Å–∞ –Ω–∞ –ó–µ–º–ª—é (—Ç–æ–ª—å–∫–æ –≤–µ—Å–∞, 200KB!)"""
        self.weights_sent += 1
        return self.model.get_weights()
    
    def get_dataset_size(self):
        return self.local_dataset_size


class GroundStationV2:
    """–ù–∞–∑–µ–º–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è v2.0 - —Ç–æ–ª—å–∫–æ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –∏ —É—Å—Ä–µ–¥–Ω—è–µ—Ç"""
    def __init__(self, global_model):
        self.global_model = global_model
        self.global_weights = [w.copy() for w in global_model.get_weights()]
        self.history = {'round': [], 'avg_loss': [], 'avg_acc': []}
        print("üåç –ù–∞–∑–µ–º–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\n")
    
    def broadcast_weights(self, satellites):
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–µ—Å–∞ –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–∏"""
        for sat in satellites:
            sat.receive_weights(self.global_weights)
    
    def aggregate_weights(self, satellites):
        """–£—Å—Ä–µ–¥–Ω–∏—Ç—å –≤–µ—Å–∞ —Å–æ —Å–ø—É—Ç–Ω–∏–∫–æ–≤"""
        all_weights = [sat.send_weights() for sat in satellites]
        all_sizes = [sat.get_dataset_size() for sat in satellites]
        total_size = sum(all_sizes)
        
        aggregated = []
        for layer_idx in range(len(all_weights[0])):
            weighted = None
            for sat_idx in range(len(satellites)):
                coeff = all_sizes[sat_idx] / total_size
                if weighted is None:
                    weighted = coeff * all_weights[sat_idx][layer_idx]
                else:
                    weighted += coeff * all_weights[sat_idx][layer_idx]
            aggregated.append(weighted)
        
        self.global_model.set_weights(aggregated)
        self.global_weights = [w.copy() for w in aggregated]


def fedleo_v2_training(satellites, ground_station, num_rounds=2, epochs=1):
    """–ì–ª–∞–≤–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º FedLEO v2.0"""
    print("\n" + "="*80)
    print("üöÄ FedLEO v2.0: –§–ï–î–ï–†–ê–¢–ò–í–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï (–û–ë–£–ß–ï–ù–ò–ï –ù–ê –°–ü–£–¢–ù–ò–ö–ê–•)")
    print("="*80)
    print(f"–°–ø—É—Ç–Ω–∏–∫–æ–≤: {len(satellites)} | –†–∞—É–Ω–¥–æ–≤: {num_rounds}")
    print("‚ú® –ö–ª—é—á–µ–≤–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å: –î–∞–Ω–Ω—ã–µ –û–°–¢–ê–Æ–¢–°–Ø –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–∞—Ö!")
    print("="*80 + "\n")
    
    for round_num in range(num_rounds):
        print(f"\n‚îå{'‚îÄ'*78}‚îê")
        print(f"‚îÇ üì° –†–ê–£–ù–î {round_num + 1}/{num_rounds}")
        print(f"‚îî{'‚îÄ'*78}‚îò\n")
        
        # 1. BROADCAST
        print(f"1Ô∏è‚É£  BROADCAST (–ó–µ–º–ª—è ‚Üí –°–ø—É—Ç–Ω–∏–∫–∏)")
        ground_station.broadcast_weights(satellites)
        print(f"   ‚úì –í–µ—Å–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ {len(satellites)} —Å–ø—É—Ç–Ω–∏–∫–æ–≤\n")
        
        # 2. TRAINING
        print(f"2Ô∏è‚É£  TRAINING (–ù–∞ —Å–ø—É—Ç–Ω–∏–∫–∞—Ö - –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û)")
        metrics = []
        for sat in satellites:
            m = sat.train_on_satellite(epochs=epochs, lr=0.01)
            metrics.append(m)
            print(f"   ‚úì –°–ø—É—Ç–Ω–∏–∫ {sat.sat_id}: Loss={m['loss']:.4f}, Acc={m['accuracy']:.4f}, Time={m['time']:.2f}s")
        print()
        
        # 3. AGGREGATE
        print(f"3Ô∏è‚É£  AGGREGATE (–ù–∞ –ó–µ–º–ª–µ)")
        ground_station.aggregate_weights(satellites)
        print(f"   ‚úì –í–µ—Å–∞ —É—Å–ø–µ—à–Ω–æ —É—Å—Ä–µ–¥–Ω–µ–Ω—ã\n")
        
        # Stats
        avg_loss = np.mean([m['loss'] for m in metrics])
        avg_acc = np.mean([m['accuracy'] for m in metrics])
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—É–Ω–¥–∞ {round_num + 1}:")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è Loss: {avg_loss:.4f}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è Accuracy: {avg_acc:.4f}")
        print(f"   ‚Ä¢ –î–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å –Ω–∞ —Å–ø—É—Ç–Ω–∏–∫–∞—Ö ‚úì")
    
    return ground_station


if __name__ == "__main__":
    print("\nüõ∞Ô∏è  === FedLEO v2.0: –û–ë–£–ß–ï–ù–ò–ï –ü–û–õ–ù–û–°–¢–¨–Æ –ù–ê –°–ü–£–¢–ù–ò–ö–ê–• ===\n")
    
    from tensorflow.keras.datasets import mnist
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ MNIST...")
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train = x_train.reshape(-1, 784).astype('float32') / 255.0
    x_test = x_test.reshape(-1, 784).astype('float32') / 255.0
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {x_train.shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤\n")
    
    def create_model():
        return keras.Sequential([
            layers.Dense(64, activation='relu', input_shape=(784,)),
            layers.Dense(10, activation='softmax')
        ])
    
    print("üõ∞Ô∏è  –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø—É—Ç–Ω–∏–∫–æ–≤...")
    satellites = []
    for i in range(4):
        start = i * 15000
        end = start + 15000
        sat = SatelliteV2(i, create_model(), x_train[start:end], y_train[start:end])
        satellites.append(sat)
    print()
    
    ground_station = GroundStationV2(create_model())
    ground_station = fedleo_v2_training(satellites, ground_station, num_rounds=2, epochs=1)
    
    print("\n" + "="*80)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï")
    print("="*80)
    
    ground_station.global_model.compile(
        optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy']
    )
    test_loss, test_acc = ground_station.global_model.evaluate(x_test, y_test, verbose=0)
    print(f"\nTest Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_acc*100:.2f}%\n")
